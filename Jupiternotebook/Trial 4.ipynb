{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "% matplotlib inline\n",
    "sns.set(color_codes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)\n",
    "df.columns = ['Sentiment', 'id', 'Date', 'Query', 'User', 'Tweet']\n",
    "df = df.drop(columns=['id', 'Date', 'Query', 'User'], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Sentiment                                              Tweet\n0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1          0  is upset that he can't update his Facebook by ...\n2          0  @Kenichan I dived many times for the ball. Man...\n3          0    my whole body feels itchy and like its on fire \n4          0  @nationwideclass no, it's not behaving at all....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beel\\gamender\\.venv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='Sentiment', ylabel='count'>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYS0lEQVR4nO3df7DddZ3f8edLQhR/IAHuUkygYWqqE9mKcAfi2m1dsxsCq4Y6aKHdJrIZszOi1bXtim3HdHGZ4tQuK1bTyUgk2W4F1tUSnWjMoPbXGuSiLAgsyxXFJMOPmETwx4qFffeP88l4uHvu5RK+51xIno+ZM+f7fX8/3+/7c53oy+/3fM/3pKqQJKlLz5vrCUiSDj+GiySpc4aLJKlzhoskqXOGiySpc/PmegLPFieeeGItXrx4rqchSc8pt9566w+qamxq3XBpFi9ezMTExFxPQ5KeU5LcP6juZTFJUucMF0lS5wwXSVLnDBdJUucMF0lS5wwXSVLnhhouSX43yZ1Jvp3k00lekOS0JDcnmUxyfZL5bezz2/pk27647zgfaPV7kpzbV1/ZapNJLuurD+whSRqNoYVLkoXAvwTGq+p04CjgIuDDwFVV9XLgALC27bIWONDqV7VxJFna9nsVsBL4RJKjkhwFfBw4D1gKXNzGMkMPSdIIDPuy2DzgmCTzgBcCDwBvAD7Ttm8GLmjLq9o6bfvyJGn166rqsar6LjAJnN1ek1V1X1X9HLgOWNX2ma6HJGkEhvYN/arak+QjwPeBvwa+DNwK/LCqHm/DdgML2/JCYFfb9/EkjwAntPrOvkP377NrSv2cts90PZ4kyTpgHcCpp556aH9on7P+zZZnfAwdXm79T6vnegoAfP/yX57rKehZ6NQP3jG0Yw/zstgCemcdpwEvA15E77LWs0ZVbayq8aoaHxv7W4/GkSQdomFeFvt14LtVtbeq/h/wWeB1wHHtMhnAImBPW94DnALQtr8U2Ndfn7LPdPV9M/SQJI3AMMPl+8CyJC9sn4MsB+4Cvgpc2MasAW5sy1vbOm37V6qqWv2idjfZacAS4BvALcCSdmfYfHof+m9t+0zXQ5I0AkMLl6q6md6H6t8E7mi9NgLvB96XZJLe5yPXtF2uAU5o9fcBl7Xj3AncQC+YvgRcWlVPtM9U3gVsB+4GbmhjmaGHJGkEhvrI/apaD6yfUr6P3p1eU8f+DHjrNMe5ArhiQH0bsG1AfWAPSdJo+A19SVLnDBdJUucMF0lS5wwXSVLnDBdJUucMF0lS5wwXSVLnDBdJUucMF0lS5wwXSVLnDBdJUucMF0lS5wwXSVLnDBdJUucMF0lS5wwXSVLnhhYuSV6R5La+16NJ3pvk+CQ7ktzb3he08UlydZLJJLcnObPvWGva+HuTrOmrn5XkjrbP1e3nlJmuhyRpNIb5M8f3VNUZVXUGcBbwU+Bz9H6++KaqWgLc1NYBzgOWtNc6YAP0goLer1meQ+/XJdf3hcUG4B19+61s9el6SJJGYFSXxZYD36mq+4FVwOZW3wxc0JZXAVuqZydwXJKTgXOBHVW1v6oOADuAlW3bsVW1s6oK2DLlWIN6SJJGYFThchHw6bZ8UlU90JYfBE5qywuBXX377G61meq7B9Rn6iFJGoGhh0uS+cCbgT+duq2dcdQw+8/UI8m6JBNJJvbu3TvMaUjSEWUUZy7nAd+sqofa+kPtkhbt/eFW3wOc0rffolabqb5oQH2mHk9SVRuraryqxsfGxg7xz5MkTTWKcLmYX1wSA9gKHLzjaw1wY199dbtrbBnwSLu0tR1YkWRB+yB/BbC9bXs0ybJ2l9jqKcca1EOSNALzhnnwJC8CfgP4nb7ylcANSdYC9wNva/VtwPnAJL07yy4BqKr9ST4E3NLGXV5V+9vyO4FrgWOAL7bXTD0kSSMw1HCpqp8AJ0yp7aN399jUsQVcOs1xNgGbBtQngNMH1Af2kCSNht/QlyR1znCRJHXOcJEkdc5wkSR1znCRJHXOcJEkdc5wkSR1znCRJHXOcJEkdc5wkSR1znCRJHXOcJEkdc5wkSR1znCRJHXOcJEkdc5wkSR1znCRJHVuqOGS5Lgkn0nyl0nuTvLaJMcn2ZHk3va+oI1NkquTTCa5PcmZfcdZ08bfm2RNX/2sJHe0fa5OklYf2EOSNBrDPnP5KPClqnol8GrgbuAy4KaqWgLc1NYBzgOWtNc6YAP0ggJYD5wDnA2s7wuLDcA7+vZb2erT9ZAkjcDQwiXJS4F/BFwDUFU/r6ofAquAzW3YZuCCtrwK2FI9O4HjkpwMnAvsqKr9VXUA2AGsbNuOraqdVVXAlinHGtRDkjQCwzxzOQ3YC3wqybeSfDLJi4CTquqBNuZB4KS2vBDY1bf/7labqb57QJ0ZejxJknVJJpJM7N2791D+RknSAMMMl3nAmcCGqnoN8BOmXJ5qZxw1xDnM2KOqNlbVeFWNj42NDXMaknREGWa47AZ2V9XNbf0z9MLmoXZJi/b+cNu+Bzilb/9FrTZTfdGAOjP0kCSNwNDCpaoeBHYleUUrLQfuArYCB+/4WgPc2Ja3AqvbXWPLgEfapa3twIokC9oH+SuA7W3bo0mWtbvEVk851qAekqQRmDfk478b+JMk84H7gEvoBdoNSdYC9wNva2O3AecDk8BP21iqan+SDwG3tHGXV9X+tvxO4FrgGOCL7QVw5TQ9JEkjMNRwqarbgPEBm5YPGFvApdMcZxOwaUB9Ajh9QH3foB6SpNHwG/qSpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzg01XJJ8L8kdSW5LMtFqxyfZkeTe9r6g1ZPk6iSTSW5Pcmbfcda08fcmWdNXP6sdf7Ltm5l6SJJGYxRnLr9WVWdU1cGfO74MuKmqlgA3tXWA84Al7bUO2AC9oADWA+cAZwPr+8JiA/COvv1WPkUPSdIIzMVlsVXA5ra8Gbigr76lenYCxyU5GTgX2FFV+6vqALADWNm2HVtVO6uqgC1TjjWohyRpBIYdLgV8OcmtSda12klV9UBbfhA4qS0vBHb17bu71Waq7x5Qn6nHkyRZl2QiycTevXuf9h8nSRps3pCP/w+rak+SXwJ2JPnL/o1VVUlqmBOYqUdVbQQ2AoyPjw91HpJ0JBnqmUtV7WnvDwOfo/eZyUPtkhbt/eE2fA9wSt/ui1ptpvqiAXVm6CFJGoGhhUuSFyV5ycFlYAXwbWArcPCOrzXAjW15K7C63TW2DHikXdraDqxIsqB9kL8C2N62PZpkWbtLbPWUYw3qIUkagWFeFjsJ+Fy7O3ge8N+r6ktJbgFuSLIWuB94Wxu/DTgfmAR+ClwCUFX7k3wIuKWNu7yq9rfldwLXAscAX2wvgCun6SFJGoGhhUtV3Qe8ekB9H7B8QL2AS6c51iZg04D6BHD6bHtIkkbDb+hLkjpnuEiSOme4SJI6Z7hIkjo3q3BJctNsapIkwVPcLZbkBcALgRPbd0zSNh3LLx61IknSkzzVrci/A7wXeBlwK78Il0eB/zK8aUmSnstmDJeq+ijw0STvrqqPjWhOkqTnuFl9ibKqPpbkV4DF/ftU1ZYhzUuS9Bw2q3BJ8sfA3wNuA55o5YO/oSJJ0pPM9vEv48DS9ogWSZJmNNvvuXwb+DvDnIgk6fAx2zOXE4G7knwDeOxgsarePJRZSZKe02YbLv9hmJOQJB1eZnu32P8c9kQkSYeP2d4t9iN6d4cBzAeOBn5SVccOa2KSpOeu2Z65vOTgcvtJ4VXAsmFNSpL03Pa0n4pcPf8DOHc245McleRbSb7Q1k9LcnOSySTXJ5nf6s9v65Nt++K+Y3yg1e9Jcm5ffWWrTSa5rK8+sIckaTRm+1Tkt/S9LkxyJfCzWfZ4D3B33/qHgauq6uXAAWBtq68FDrT6VW0cSZYCFwGvAlYCn2iBdRTwceA8YClwcRs7Uw9J0gjM9szlTX2vc4Ef0bs0NqMki4DfBD7Z1gO8AfhMG7IZuKAtr2rrtO3L+y7BXVdVj1XVd4FJ4Oz2mqyq+6rq58B1wKqn6CFJGoHZfuZyySEe/4+A3wMOfmZzAvDDqnq8re/mF4/uXwjsav0eT/JIG78Q2Nl3zP59dk2pn/MUPZ4kyTpgHcCpp5769P86SdJAs70stijJ55I83F5/1s5KZtrnjcDDVXVrJzMdgqraWFXjVTU+NjY219ORpMPGbC+LfQrYSu93XV4GfL7VZvI64M1JvkfvktUbgI8CxyU5eMa0CNjTlvcApwC07S8F9vXXp+wzXX3fDD0kSSMw23AZq6pPVdXj7XUtMOP/1a+qD1TVoqpaTO8D+a9U1T8Hvgpc2IatAW5sy1vbOm37V9qDMrcCF7W7yU4DlgDfAG4BlrQ7w+a3HlvbPtP1kCSNwGzDZV+S3zp4l1aS36J3hnAo3g+8L8kkvc9Hrmn1a4ATWv19wGUAVXUncANwF/Al4NKqeqJ9pvIuYDu9u9FuaGNn6iFJGoHZPlvst4GP0btFuIA/B94+2yZV9TXga235Pnp3ek0d8zPgrdPsfwVwxYD6NmDbgPrAHpKk0ZhtuFwOrKmqAwBJjgc+Qi90JEl6ktleFvsHB4MFoKr2A68ZzpQkSc91sw2X5yVZcHClnbnM9qxHknSEmW1A/Gfg60n+tK2/lQGfgUiSBLP/hv6WJBP0vqsC8Jaqumt405IkPZfN+tJWCxMDRZL0lJ72I/clSXoqhoskqXOGiySpc4aLJKlzhoskqXOGiySpc4aLJKlzhoskqXOGiySpc4aLJKlzhoskqXNDC5ckL0jyjSR/keTOJL/f6qcluTnJZJLrk8xv9ee39cm2fXHfsT7Q6vckObevvrLVJpNc1lcf2EOSNBrDPHN5DHhDVb0aOANYmWQZ8GHgqqp6OXAAWNvGrwUOtPpVbRxJlgIXAa8CVgKfSHJUkqOAjwPnAUuBi9tYZughSRqBoYVL9fy4rR7dXkXvsf2fafXNwAVteVVbp21fniStfl1VPVZV3wUmgbPba7Kq7quqnwPXAavaPtP1kCSNwFA/c2lnGLcBDwM7gO8AP6yqx9uQ3cDCtrwQ2AXQtj8CnNBfn7LPdPUTZugxdX7rkkwkmdi7d+8z+EslSf2GGi5V9URVnQEsonem8cph9nu6qmpjVY1X1fjY2NhcT0eSDhsjuVusqn4IfBV4LXBckoM/UrYI2NOW9wCnALTtLwX29den7DNdfd8MPSRJIzDMu8XGkhzXlo8BfgO4m17IXNiGrQFubMtb2zpt+1eqqlr9onY32WnAEuAbwC3AknZn2Hx6H/pvbftM10OSNAKz/pnjQ3AysLnd1fU84Iaq+kKSu4DrkvwB8C3gmjb+GuCPk0wC++mFBVV1Z5Ib6P3E8uPApVX1BECSdwHbgaOATVV1ZzvW+6fpIUkagaGFS1XdDrxmQP0+ep+/TK3/DHjrNMe6ArhiQH0bsG22PSRJo+E39CVJnTNcJEmdM1wkSZ0zXCRJnTNcJEmdM1wkSZ0zXCRJnTNcJEmdM1wkSZ0zXCRJnTNcJEmdM1wkSZ0zXCRJnTNcJEmdM1wkSZ0zXCRJnTNcJEmdG1q4JDklyVeT3JXkziTvafXjk+xIcm97X9DqSXJ1kskktyc5s+9Ya9r4e5Os6aufleSOts/VSTJTD0nSaAzzzOVx4F9V1VJgGXBpkqXAZcBNVbUEuKmtA5wHLGmvdcAG6AUFsB44h95PF6/vC4sNwDv69lvZ6tP1kCSNwNDCpaoeqKpvtuUfAXcDC4FVwOY2bDNwQVteBWypnp3AcUlOBs4FdlTV/qo6AOwAVrZtx1bVzqoqYMuUYw3qIUkagZF85pJkMfAa4GbgpKp6oG16EDipLS8EdvXttrvVZqrvHlBnhh5T57UuyUSSib179x7CXyZJGmTo4ZLkxcCfAe+tqkf7t7Uzjhpm/5l6VNXGqhqvqvGxsbFhTkOSjihDDZckR9MLlj+pqs+28kPtkhbt/eFW3wOc0rf7olabqb5oQH2mHpKkERjm3WIBrgHurqo/7Nu0FTh4x9ca4Ma++up219gy4JF2aWs7sCLJgvZB/gpge9v2aJJlrdfqKcca1EOSNALzhnjs1wH/ArgjyW2t9m+BK4EbkqwF7gfe1rZtA84HJoGfApcAVNX+JB8CbmnjLq+q/W35ncC1wDHAF9uLGXpIkkZgaOFSVf8HyDSblw8YX8Cl0xxrE7BpQH0COH1Afd+gHpKk0fAb+pKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTOGS6SpM4ZLpKkzhkukqTODS1ckmxK8nCSb/fVjk+yI8m97X1BqyfJ1Ukmk9ye5My+fda08fcmWdNXPyvJHW2fq5Nkph6SpNEZ5pnLtcDKKbXLgJuqaglwU1sHOA9Y0l7rgA3QCwpgPXAOcDawvi8sNgDv6Ntv5VP0kCSNyNDCpar+F7B/SnkVsLktbwYu6KtvqZ6dwHFJTgbOBXZU1f6qOgDsAFa2bcdW1c6qKmDLlGMN6iFJGpFRf+ZyUlU90JYfBE5qywuBXX3jdrfaTPXdA+oz9fhbkqxLMpFkYu/evYfw50iSBpmzD/TbGUfNZY+q2lhV41U1PjY2NsypSNIRZdTh8lC7pEV7f7jV9wCn9I1b1Goz1RcNqM/UQ5I0IqMOl63AwTu+1gA39tVXt7vGlgGPtEtb24EVSRa0D/JXANvbtkeTLGt3ia2ecqxBPSRJIzJvWAdO8mng9cCJSXbTu+vrSuCGJGuB+4G3teHbgPOBSeCnwCUAVbU/yYeAW9q4y6vq4E0C76R3R9oxwBfbixl6SJJGZGjhUlUXT7Np+YCxBVw6zXE2AZsG1CeA0wfU9w3qIUkaHb+hL0nqnOEiSeqc4SJJ6pzhIknqnOEiSeqc4SJJ6pzhIknqnOEiSeqc4SJJ6pzhIknqnOEiSeqc4SJJ6pzhIknqnOEiSeqc4SJJ6pzhIknqnOEiSercYRsuSVYmuSfJZJLL5no+knQkOSzDJclRwMeB84ClwMVJls7trCTpyHFYhgtwNjBZVfdV1c+B64BVczwnSTpizJvrCQzJQmBX3/pu4Jypg5KsA9a11R8nuWcEcztSnAj8YK4nMdfykTVzPQX9bf7bPGh9ujjK3x1UPFzDZVaqaiOwca7ncThKMlFV43M9D2kq/22OxuF6WWwPcErf+qJWkySNwOEaLrcAS5KclmQ+cBGwdY7nJElHjMPyslhVPZ7kXcB24ChgU1XdOcfTOtJ4uVHPVv7bHIFU1VzPQZJ0mDlcL4tJkuaQ4SJJ6pzhok752B09myU5Ksm3knxhrudyuDNc1Bkfu6PngPcAd8/1JI4Ehou65GN39KyVZBHwm8An53ouRwLDRV0a9NidhXM0F2mqPwJ+D/ibOZ7HEcFwkXTYS/JG4OGqunWu53KkMFzUJR+7o2er1wFvTvI9epdr35Dkv83tlA5vfolSnUkyD/grYDm9ULkF+Gc+HUHPJkleD/zrqnrjHE/lsHZYPv5Fc8PH7kg6yDMXSVLn/MxFktQ5w0WS1DnDRZLUOcNFktQ5w0WS1DnDRXqGkvy7JHcmuT3JbUnOOYRjnJHk/L71Nw/7qdJJXp/kV4bZQ0cuv+ciPQNJXgu8ETizqh5LciIw/xAOdQYwDmwDqKqtwNau5jmN1wM/Bv58yH10BPJ7LtIzkOQtwCVV9aYp9bOAPwReDPwAeHtVPZDka8DNwK8BxwFr2/okcAy9Jxv8x7Y8XlXvSnIt8NfAa4BfAn4bWA28Fri5qt7eeq4Afh94PvCdNq8ft0eebAbeBBwNvBX4GbATeALYC7y7qv53p//h6IjmZTHpmfkycEqSv0ryiST/OMnRwMeAC6vqLGATcEXfPvOq6mzgvcD69vMEHwSur6ozqur6AX0W0AuT36V3RnMV8Crgl9sltROBfw/8elWdCUwA7+vb/wetvoHeo0++B/xX4KrW02BRp7wsJj0D7czgLOBX6Z2NXA/8AXA6sCMJ9B6F80Dfbp9t77cCi2fZ6vNVVUnuAB6qqjsAktzZjrGI3g+0/d/Wcz7w9Wl6vmX2f6F0aAwX6RmqqieArwFfa//jfylwZ1W9dppdHmvvTzD7/w4e3Odv+pYPrs9rx9pRVRd32FM6ZF4Wk56BJK9IsqSvdAa9n9Edax/2k+ToJK96ikP9CHjJM5jKTuB1SV7eer4oyd8fck9pWoaL9My8GNic5K4kt9O7NPVB4ELgw0n+ArgNeKpbfr8KLG23Mv/TpzuJqtoLvB34dJvH14FXPsVunwf+Sev5q0+3pzQT7xaTJHXOMxdJUucMF0lS5wwXSVLnDBdJUucMF0lS5wwXSVLnDBdJUuf+P2ZZGWthg2ZKAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.Sentiment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df['Sentiment'] = df.Sentiment.replace(4, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n",
    "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n",
    "urls = re.compile(r\"https?://\\S+\")\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = hashtags.sub(' hashtag', text)\n",
    "    text = mentions.sub(' entity', text)\n",
    "    return text.strip().lower()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df['Tweet'] = df.Tweet.apply(process_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   Sentiment                                              Tweet\n0          0  entity  - awww, that's a bummer.  you shoulda ...\n1          0  is upset that he can't update his facebook by ...\n2          0  entity i dived many times for the ball. manage...\n3          0     my whole body feels itchy and like its on fire\n4          0  entity no, it's not behaving at all. i'm mad. ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>entity  - awww, that's a bummer.  you shoulda ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can't update his facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>entity i dived many times for the ball. manage...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>entity no, it's not behaving at all. i'm mad. ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "labels = df.Sentiment.values\n",
    "text = df.Tweet.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\beel\\gamender\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2211: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_mask = []\n",
    "for i in text:\n",
    "    encoded_data = tokenizer.encode_plus(\n",
    "        i,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt')\n",
    "    input_ids.append(encoded_data['input_ids'])\n",
    "    attention_mask.append(encoded_data['attention_mask'])\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_mask = torch.cat(attention_mask, dim=0)\n",
    "labels = torch.tensor(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size -  1280000\n",
      "Validation Size -  320000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_mask, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('Training Size - ', train_size)\n",
    "print('Validation Size - ', val_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(40000, 10000)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_dataset, sampler=RandomSampler(train_dataset),\n",
    "                      batch_size=32)\n",
    "val_dl = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset),\n",
    "                    batch_size=32)\n",
    "len(train_dl), len(val_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dl) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    label_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == label_flat) / len(label_flat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def evaluate(dataloader_test):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    for batch in dataloader_test:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    loss_val_avg = loss_val_total / len(dataloader_test)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    return loss_val_avg, predictions, true_vals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "899d4297a4b0452a875bea4b135472b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 1:   0%|          | 0/40000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36fd6658fbc34f30a9657b35bbe4d09d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.32291949986191465\n",
      "Validation loss: 0.29761020266003907\n",
      "Accuracy: 0.874090625\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(train_dl, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2],\n",
    "                  }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(train_dl)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(val_dl)\n",
    "    val_acc = accuracy(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'Accuracy: {val_acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "('./tokenizer_config.json',\n './special_tokens_map.json',\n './vocab.txt',\n './added_tokens.json')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = './'\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "output_dir = './'\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def Sentiment(sent):\n",
    "    output_dir = '../models/models/bert-custom'\n",
    "    tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "    model_loaded = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_id = encoded_dict['input_ids']\n",
    "\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    input_id = torch.LongTensor(input_id)\n",
    "    attention_mask = torch.LongTensor(attention_mask)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_loaded = model_loaded.to(device)\n",
    "    input_id = input_id.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    index = logits.argmax()\n",
    "    return index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\beel\\gamender\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2211: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ans = Sentiment(\n",
    "    'i love you')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "if ans == 1:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "('models/bert-custom\\\\tokenizer_config.json',\n 'models/bert-custom\\\\special_tokens_map.json',\n 'models/bert-custom\\\\vocab.txt',\n 'models/bert-custom\\\\added_tokens.json')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'models/bert-custom'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "('models_loaded/distilbert-custom\\\\tokenizer_config.json',\n 'models_loaded/distilbert-custom\\\\special_tokens_map.json',\n 'models_loaded/distilbert-custom\\\\vocab.txt',\n 'models_loaded/distilbert-custom\\\\added_tokens.json')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'models_loaded/distilbert-custom'\n",
    "model_loaded.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}